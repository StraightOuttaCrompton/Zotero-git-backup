Optimal Multiple Stopping Rule for Warm-Starting Sequential Selection
Mathilde Fekom Nicolas Vayatis Argyris Kalogeratos

arXiv:2002.05160v1 [cs.AI] 12 Feb 2020

Abstract— In this paper we present the Warm-starting Dynamic Thresholding algorithm, developed using dynamic programming, for a variant of the standard online selection problem. The problem allows job positions to be either free or already occupied at the beginning of the process. Throughout the selection process, the decision maker interviews one after the other the new candidates and reveals a quality score for each of them. Based on that information, she can (re)assign each job at most once by taking immediate and irrevocable decisions. We relax the hard requirement of the class of dynamic programming algorithms to perfectly know the distribution from which the scores of candidates are drawn, by presenting extensions for the partial and no-information cases, in which the decision maker can learn the underlying score distribution sequentially while interviewing candidates.
I. INTRODUCTION
Sequential Selection Problems (SSPs) occur in several reallife situations. A common characteristic of such decision processes is that decisions need to be immediate and irrevocable. For instance, at an emergency healthcare unit, patients arrive sequentially seeking for medical help [8]. Other examples are found in kidney exchanges [4], auctions [9], robotic sampling [5], and most straightforwardly in recruitment processes that involve sequential interviews of job-seekers by a decision maker (DM), who immediately takes hiring or rejection decisions [3]. For clarity, we adopt the terminology of the latter problem, e.g. candidates are interviewed, hiring means selecting, ﬁring is deselecting, etc.
In the most well-known SSP, the secretary problem [7], [10], n ∈ N∗ candidates are sequentially interviewed for a single job position, and a hire puts an end to the recruitment process. Its multi-choice extension, also called multiple stopping problem, has been extensively studied [9], [2], [1], and terminates when the desired number of b ∈ N∗ hired have been decided. In the hiring problem [3], the DM’s task is to grow the company as much as possible while keeping maximal the average score of the hired employees; therefore, there is no limit in the number of job positions. The hiring-above-themean policy was proposed, which selects a candidate when his score exceeds the average score of the current employees (changes over time). This policy is an efﬁcient and easy to implement, yet notably dependent on the score distribution and sensitive to the quality of the ﬁrst hires.
What we call as the full-information case, assumes that the distribution from which the scores of candidates are sampled is known to the DM. In [11], dynamic programming
The authors are with Universite´ Paris-Saclay, ENS ParisSaclay, CNRS, Centre Borelli, F-94235, Cachan, France. Emails: {fekom, vayatis, kalogeratos}@cmla.ens-cachan.fr.
Part of this work was funded by the French Railway Company, SNCF, and the IdAML Chair hosted at ENS Paris-Saclay.

is employed to compute the optimal stopping rule for each candidate, i.e. the score threshold to beat in order to be hired. This threshold depends on his arrival time and on the number of jobs positions that remain to be ﬁlled.
One important limitation of all the aforementioned settings is that they begin with an empty selection set. The case of performing a selection starting with a set of items at hand was only recently introduced in [6]. There, a preselection is composed of the pre-existing items that can then be replaced, by selecting better items from those that appear sequentially, to produce the ﬁnal selection. More speciﬁcally, the authors present the so-called Warm-starting Sequential Selection Problem (WSSP) where the DM can perform at most one update per job position. This setting can also suit well to multi-round applications where the output of a round is the input of the subsequent one.
The Cutoff-based Cost Minimization algorithm from the same work [6] makes no assumption on the distribution of candidates’ scores. It splits the process into two phases: the learning phase in which the DM learns an acceptance threshold from candidates that are getting rejected by default, and thereafter, the selection phase which uses that threshold to accept or reject from the rest candidates. Despite its biased rule, which is due to the disregard of the early-arriving candidates, the strategy can be efﬁcient and robust to score changes, provided an appropriately set learning phase size.
Important to note, when the score distribution is known, the cutoff-based strategies are not optimal and policies derived from dynamic programming are more suitable. To the best of our knowledge, there exists no such warm-starting strategy in the literature.
Contribution. Inspired by the warm-starting aspect of the WSSP [6], we propose the Warm-starting Dynamic Thresholding (WDT) algorithm that attributes to each incoming candidate a threshold value to beat according to: i) its arrival time, ii) the current number of empty job positions, and iii) the current number of positions occupied by initial employees (i.e. available employees that can be replaced). The threshold value to beat is computed by means of dynamic programming, adapted to the warm-starting scenario. The algorithm is easy to implement and gives each candidate a chance to be hired regardless his arriving time. WDT’s downside lies in the assumption that the score distribution is known. We relax this requirement by ﬁrst considering the partial information case where the DM only knows the nature of the distribution, and then the no-information case where the threshold is purely rank-based. We show with simulations that the WDT outperforms existing methods in the warm-starting scenario.

II. SETTING

The Sequential Selection Problem (SSP) of interest is the following: n ∈ N∗ candidates are sequentially interviewed

…

S1

S2

S3

S4

S5

S6

S7

S8

by a decision maker (DM) who has the task of managing a limited budget of b ∈ N∗, b ≤ n, interchangeable job positions.

Job positions

Initially, r ≤ b positions are empty as some employees have

become permanently unavailable, while the rest b − r are

initially occupied by existing employees that form a set called

preselection. Available and unavailable employees constitute Legend

a reference set for the DM. Once candidate j arrives, the DM observes his score Sj ∈ R, which, like all scores, it is assumed to follow a known distribution fS. In our notations,

Jobs:

Score to beat for cand. j when X jobs are empty and Y preselected have a job

Empty

Filled by a preselected

/ S

S rejected/accepted candidate 

with score S

Filled by a candidate

an added dot on top of a variable refers to the preselection, e.g.

S˙ = (S˙(1), S˙(2), ..., S˙(b−r)) gives the score of each preselected
employee. For convenience, the latter vector is considered to be sorted in decreasing order, i.e. S˙(1) and S˙(b−r) are
respectively the best and the worst scores of the preselected

Fcaign.di1d.ateD,TeS12mj,3,onissTtrc2a2ot,mi3opnaTore3f1d,t3hteo WaTnD40a,T3ssaolcgTio5a0rt,ie2thdmaT.c60cT,e2hpetaTsnc7c0oe,r1ethorfeTsa8h0n,o1ilndcoTmjXi,nYg,
where X and Y are respectively the current number of empty positions and $T_1^{2,3}$ \hspace{0.0mm} $T_2^{2,3}$ \hspace{0.0mm} $T_3^{1,3}$ \hspace{0.0mm} $T_4^{0,3}$ \hspace{0.0mm} $T_5^{0,2}$ \hspace{0.0mm}
$T_6^{0,2}$ \hspace{0.0mm} $T_7^{0,1}$ \hspace{0.0mm} $T_8^{0,1}$
that of positions occupied by preselected employees. Accepted candidates
(blue circle) ﬁrst ﬁll empty positions and then, if they are competitive enough,

employees. Here are the basic rules of the game:

take a preselected employee’s positions (e.g. the 5-th candidate).

R1. Each decision (i.e. hire or not) shall be immediate and irrevocable, which means that every position can be assigned (or reassigned) at most once throughout the selection process.
R2. The DM must at least ﬁll the empty job positions by hiring r candidates.
R3. Once no empty position is left, the DM can still hire an incoming candidate by removing one of the employees of the preselection from his position (only ﬁre on hire).
The following deﬁnition is a score-based adaptation of the Warm-starting Sequential Selection Problem (WSSP) proposed in [6], where here the DM initially knows also the distribution from which candidates’ scores are drawn.

that, since the DM is forced to ﬁll the b positions by the end

of the process, it holds:

b−r i=1

A˙ (j),n

+

n j=1

Aj

=

b.

III. WARM-STARTING DYNAMIC THRESHOLDING
Here, we present the Warm-starting Dynamic Thresholding (WDT) method to solve optimally the distribution-aware WSSP of Deﬁnition 1. Without loss of generality, we consider non-negative i.i.d. scores Sj ≥ 0, ∀j, and that the best- (resp. worst-) skilled individual has the highest (resp. lowest) score.

A. Threshold-based algorithm

Deﬁnition 1: Distribution-aware WSSP is the online selection process described by elements of three categories: 1) Background
B = (b, n, fS, S˙ ): collection of elements initially at DM’s knowledge or disposition, including:
N • n ∈ ∗: ﬁnite number of candidates to appear; N • b ∈ ∗, b ≤ n: number of resources;
• fS: the distribution generating candidates’ scores; • S˙ = (S˙(1), ..., S˙(b−r)) ∈ Rb−r; S˙(j) ∼ fS, ∀j: scores of
the preselection.
2) Process
• S = (S1, ..., Sn) ∈ Rn; Sj ∼ fS, ∀j: candidates’ scores; • A = (A1, ..., An) ∈ {0, 1}n: sequence of decisions for
candidates, i.e. Aj = 1 if the j-th candidate gets hired.
3) Evaluation
• The reward is evaluated at the end of the process by:

b−r

n

φB(S, A) = S˙(i)A˙ (i),n + Sj Aj ≥ 0, (1)

i=1

j=1

where A˙ (i),n ∈ {0, 1} indicating if the i-th preselected employee kept his position after n candidate interviews.
The evaluation criterion to maximize is therefore the expectation of the above reward function, E[φB(S, A)]. Note

The idea behind the strategy is to ﬁnd the optimal
acceptance threshold Tj ∈ R that the j-th arriving candidate should beat in order to be hired, ∀j ∈ {1, ..., n}; see
the example of Fig. 2. Note that, in order to be optimal,
this threshold must depend on the state of the ongoing selection process. Therefore, we write Tj = TjXj,Yj , where Xj ∈ {0, ..., r} positions are still empty and Yj ∈ {0, ..., b−r} jobs are still occupied by preselected employees, i.e. after j − 1 ∈ N∗ interviews and while the j-th candidate is being
interviewed. Using the notations of Deﬁnition 1 we get:

j−1

r

Xj := max r − Ai, 0 and Yj := A˙ (i),j. (2)

i=1

i=1

To simplify our notations, we omit the dependency of Xj and Yj to j, and we simply write X and Y to refer to their value at the implied step j of the selection process.

Value function. The fundamental question remains how to compute the thresholds optimally. The solution can be found via dynamic programming where the value function, which is the expected value of the regret here, is computed for each possible scenario. Let VjX,Y ∈ R be this value function when j − 1 ∈ N∗ candidates have been interviewed so far.
Before going into the method’s details, we can deduce the following remarks from the rules that constrain the process:

Remark 1: The second rule, R2, implies that if X ≥ n−j, then VjX,Y = 0, ∀ Y . Thus, the last incoming candidates might be accepted by default, and this leads to X = 0 when j = n.
Remark 2: R3 implies that if X = 0, then Y = b − r, ∀j.
Remark 3: From R2 and R3 we deduce that X and Y are non-increasing with j: throughout the process the number of job positions assigned to candidates cannot decrease, while those for the preselected employees cannot increase.
To compute VjX,Y we work by means of backward induction. First, we consider the extreme case that n candidates are automatically rejected, and compute the value function Vnr,b−r. Here, either X = 0 and r = 0, i.e. each position is occupied by a preselected employee, or Vnr,b−r = 0 because one or more positions are empty. The induction then goes to the ﬁrst non-zero value function, which is when n − r candidates get automatically rejected: there, the only option is to hire the r last candidates to arrive (see Remark 1), hence:

Algorithm 1 Warm-starting Dynamic Thresholding (WDT)

Input: the evaluation table of the value function VjX,Y where b, r, and n are the numbers of resp. job positions, initially empty among them, and sequentially incoming candidates; A˙ 0 = (A˙ (1),0, ..., A˙ (b−r),0) = (1, ..., 1) is the initial status of the preselected employees. Output: the set of ﬁnal job assignments A˙ n ∈ {0, 1}b−r, and A ∈ {0, 1}n.

1: X ← r

// nb. of empty jobs

2: Y ← b − r

// nb. of jobs occupied by preselected employees

3: for j = 1 to n do

4:

Tj ← VjX+,1Y − max(VjX+−1 1,Y , VjX+,1Y −1)

5: if Sj > Tj then

6:

Aj ← 1

7:

if X > 0 then

// see Proposition 2 // accept candidate

8:

X ← max(X − 1, 0)

// ﬁll one empty position

9:

else

10:

A˙ (Y ),j ← 0 // remove job from a preselected employee

11:

Y ←Y −1

12:

end if

13: else

14:

Aj ← 0

15: end if

16: end for





n

b−r

b−r

E Vnr−,br−+r1 = 

Sj + S˙(i) = rµ + S˙(i), (3)

j=n−r+1

i=1

i=1

where µ is the mean of the known score distribution fS. One step back, Vnr−,br−r is evaluated by accounting every
option: either the (n − r)-th candidate gets rejected and the last r candidates get hired, leading to the reward of Vnr−,br−+r1 (Eq. 3), or the (n−r)-th candidate gets hired and in this case
we should, again, present two options. The DM can lower by
one either the number of empty job positions, or the number
of preselected employees that will keep their positions at
the end of the selection. This reasoning is generalized to the following recurrent value functions ∀j ∈ {1, ...n}:

E VjX,Y = max VjX+,1Y, Sj + max(VjX+−1 1,Y, VjX+,1Y −1) . (4)

The ﬁrst term in the outer max(·) corresponds to the option of rejecting the j-th candidate, while the second term is the option of accepting him. Two observations can be made: i) if the goal is to minimize instead of maximize the objective, then max(·) should be replaced by min(·) functions; ii) results of [11], and speciﬁcally their Theorem 3 in Sec. 3, can be retrieved by setting Y = 0 that implies VjX+,1Y −1 = 0.

Recurrence relation. Thanks to our backward induction formulation, we enunciate a generic formula for the recurrence relation of the value function.

Proposition 1: Let a WSSP with a population of i.i.d.

scores S ∈ [α, β], each drawn from a known distribution fS

with

cumulative

distribution

function

FS(x) =

x α

fS

(y)dy.

Having processed j−1 interviews, X ∈ {0, ..., r} job positions

are empty and Y ∈ {0, ..., b − r} are occupied by preselected

employees. Then, the recurrence relation of Eq. 4 becomes:

β

VjX,Y − VjX+,1Y = ZjX+,Y1

FS (ZjX+,Y1 ) − 1

+

sfS(s)ds, (5)
ZjX+,1Y

where ZjX+,Y1 := VjX+,1Y − max(VjX+−1 1,Y , VjX+,1Y −1).

The proof1 uses max(A, B) = A1{A > B} + B1{A ≤ B} in order to compute the expectation.

Optimal threshold. Evidently, the j-th candidate must be accepted if the value function associated to the option of accepting him is larger than that of rejecting him. According to Eq. 4, the latter amounts to choosing the optimal threshold deﬁned in the following proposition that maximize the expectation of the reward.
Proposition 2: Let a WSSP where j − 1 interviews have been processed, X ∈ {0, ..., r} job positions are empty, and Y ∈ {0, ..., b−r} are occupied by preselected employees. The optimal acceptance threshold for candidate j is deﬁned as:

TjX,Y = VjX+,1Y − max(VjX+−1 1,Y , VjX+,1Y −1).

(6)

Essentially, the j-th candidate is accepted if his score beats the corresponding threshold, i.e. Aj = 1{Sj > TjX,Y }.
The WDT procedure works with the optimal threshold
described above and is described in Algorithm 1.

B. Special case: uniform distribution

Consider that scores are uniformly distributed in [α, β].

The cumulative and probability density functions being easily

computed, allows the recurrence relation to get simpliﬁed.

Proposition 3: Set Sj ∼ U(α, β), ∀j ≤ n. Then, Proposition 1 becomes:

VjX,Y

− VjX+,1Y

=

ZjX+,Y1 2 − 2αZjX+,Y1 2(β − α)

+β2

− ZjX+,Y1 ,

(7)

where ZjX+,Y1 = VjX+,1Y − max(VjX+−1 1,Y , VjX+,1Y −1).

The

proof??

uses

the

fact

that

FS(x) =

x−α β−α

and

fS(x) =

1 β−α

for a uniform distribution.

Example. Set α = 0 and β = 1, b = 3, r = 2, and n = 14. Tab. I displays the evaluation of the value function

1A separate Appendix, containing detailed proofs, can be found as a supplement ﬁle.

Y X V1X,Y

0

1 2

0.893 1.719

0 0.907 1 1 1.756
2 2.547

V2X,Y
0.886 1.702
0.902 1.742 2.523

V3X,Y
0.879 1.683
0.897 1.729 2.496

V4X,Y
0.871 1.661
0.891 1.712 2.465

V5X,Y
0.861 1.636
0.885 1.694 2.431

V6X,Y
0.850 1.606
0.877 1.673 2.391

V7X,Y
0.836 1.571
0.869 1.650 2.345

V8X,Y
0.823 1.529
0.859 1.621 2.290

V9X,Y
0.800 1.476
0.847 1.588 2.224

V1X0 ,Y
0.775 1.409
0.833 1.547 2.142

V1X1 ,Y
0.741 1.320
0.816 1.495 2.036

V1X2 ,Y
0.768 1.195
0.795 1.428 1.894

V1X3 ,Y
0.732 1.000
0.979 1.333 1.682

V1X4 ,Y
0.682 0.000
0.979 1.182 0.000

TABLE I
EVALUATION OF THE VjX,Y FUNCTION AT EACH STEP j = 1, ..., 14. THE DISTRIBUTION OF THE SCORES IS Sj ∼ U (0, 1), AND THERE IS b − r = 2 − 1 = 1 INITIALLY NON-EMPTY JOB POSITION OCCUPIED BY AN EMPLOYEE WITH SCORE S˙(1) = 0.682.

VjX,Y at each step of the selection process. Recall that, at the respective step j, X ∈ {1, ..., b} is the number of empty job positions, and Y ∈ {0, 1} is the DM’s hiring
decision. Now, imagine the following sequence of scores: S = (0.498, 0.858, 0.749, 0.398, ...) and S˙ = (0.682) is the
score of the preselected employee. We are determining the acceptance threshold sequentially. Note that, since r = 0, Vj0,0 = 0. For the ﬁrst incoming candidate, j = 1, r = 2 job positions are empty, i.e. X = 2 and b − r = 1 position is occupied by a preselected employee, i.e. Y = 1. The ﬁrst candidate is rejected since T12,1 = V22,1 − max(V21,1, V22,0) = 2.523 − max(1.742, 1.702) = 0.781 > 0.498. The second threshold reads T22,1 = V32,1 − max(V31,1, V32,0) = 2.496 − max(1.729, 1.683) = 0.767 < 0.858, which allows the accep-
tance of the second candidate. The following threshold is then, T31,1 = 0.832, thus the third candidate is rejected. The process continues this way until the sequence is ﬁnished.
Rank-based setting. When the score distribution is either
unknown (no-information case), or does not exhibit a closed-
form cumulative density function, the DM can only rely
on a relative evaluation of the candidates. In practice, she
can assign a relative rank to each incoming candidate by
comparing him to those already examined (let the best one
be ranked ﬁrst).
In that case, the acceptance threshold is rank-based, hence TjX,Y stands for the absolute rank (which cannot be known, though) that the j-th candidate needs to exceed to get selected.
Conveniently, the absolute ranks of a set follow a discrete
uniform distribution that exhibits a closed-form description. Then, the threshold value for the j-th candidate is computed
using Proposition 2 and, following the same reasoning as in
Proposition 3, we get the following simpliﬁed expression:

VjX,Y

= VjX+,1Y

− ZjX+,Y1 2 − ZjX+,Y1 2(n + b)

,

(8)

where ZjX+,Y1 = VjX+,1Y − min(VjX+−1 1,Y , VjX+,1Y −1).
As mentioned, the DM cannot know the absolute rank
of a candidate before ﬁnishing all interviews. She can still,
though, estimate it knowing his relative rank and by taking
into account the proportion of candidates that has already
been examined. More precisely, the j-th candidate has relative rank denoted by Zjrel ∈ N∗ after the examination of j + b − r individuals (including the preselected employees), and the absolute rank denoted by Zjabs that he would have after the examination of n + b − r individuals. Hence, we set Zjrel =

j+b−r n+b−r

Zjabs

and,

thereby,

the

practical

threshold

of

relative

rank that the j-th candidate must exceed to be accepted is:

τjX,Y

=

j+b−r n+b−r

TjX,Y

.

(9)

IV. SIMULATION RESULTS

A. Simulations parameters

The WSSP setting takes as input the reference set (containing available and unavailable employees) and the sequence of candidates, and outputs a selection of size b. A very interesting feature of this conﬁguration is that it enables multi-round applications where the output selection of a round can be fed as input for the consecutive round. For instance, it is natural to imagine periodic or reoccurring recruitment processes for large organizations that have several human resources to manage. Inspired by [6], we thereby repeat the WSSP process K ∈ N∗ times. Each repetition k ≤ K, called round, is in essence a warm-starting selection. The round starts with b−r available employees and assumes that unavailability occurs uniformly at random among the b employees of the reference set (those selected during the previous round). Overall, the K rounds form a Multi-round Sequential Selection Problem (MSSP) where the DM’s objective is the upkeep of a highlyskilled group of employees throughout the entire process.
In the simulations, a population of N = 10000 job-seekers is considered, and that n = 100 interviews take place in each of the K = 10 considered rounds. The candidates’ scores are drawn from a given distribution and remain ﬁxed during the process. The preselected employees of the ﬁrst round are chosen uniformly at random from the population, and hence, carry an average quality score. We desire to compare our online strategy, the WDT, to the best an ofﬂine strategy achieves, i.e. in the case that the DM could examine the candidates altogether as a batch. Therefore, instead of the reward, in the ﬁgures we plot the regret deﬁned as φk = |φoff,k − φk|, ∀k ≤ K, where φoff,k and φk are respectively the ofﬂine and online reward.

B. Score-based setting
Fig. 2 displays the average regret φk in different settings, namely Si,k ∼ U (0, 1) (top row) and Si,k ∼ Exp(1), ∀i, k (bottom row). Let us start by focusing on the plain line curves, one of which is the RAND baseline (grey line) that decides for the hires at random. A ﬁrst straightforward observation is that the average regret has similar inefﬁcient behavior for both distributions. In the following description, we therefore focus on the uniform distribution.

Secondly, the subﬁgures on the left assume r = 0, hence the process always starts with b empty positions, whereas on the right it is assumed r = b, thus the process starts with b positions occupied by preselected employees. In the ﬁrst case, since the employees do not quit their position in-between two subsequent rounds, the DM cannot deteriorate the selection, and might even improve the set of employees through time by replacing initial employees with more skilled candidates. The regret naturally goes to zero, and it does go faster for the proposed WDT than for instance the MEAN or CCM∗ strategies. Note that CCM∗ is merely the Cutoff-based Cost Minimization algorithm with optimal size of learning phase [6]. In the second case (r = 0), the regret does not necessarily converge towards zero; neither MEAN nor CCM∗ manage to keep a low average regret. This phenomenon is explained as follows: progressively, the average score of the employees of the previous round gets so competitive for the incoming candidates that it forces the DM to select the last-arriving ones by default to prevent ending up with having empty positions after all the interviews (see the rule R2 in Section II).

0.5

0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0

0

0

2

4

6

8

10

0

2

4

6

8

10

3

3

2.5

2.5

2

2

1.5

1.5

1

1

0.5

0.5

0

0

0

2

4

6

8

10

0

2

4

6

8

10

(c) no resignations (r = 0)

(d) max resignations (r = b)

C. Full, partial, and no-information settings
In Fig. 2, we also show the performance of the algorithms for cases with different levels of DM’s knowledge for the score distribution fS. In the full-information case (plain line), fS is perfectly known. In the partial information case (dashed line), DM knows only the shape of the fS (e.g. uniform, normal, exponential, etc.) and needs to learn its parameters (e.g. lower and upper bounds, mean, etc.). Finally, the noinformation case (dotted line) is when the DM does not hold any information about fS (e.g. the shape, as discussed in the example of Section III-B), or not even a way to compute an absolute score per candidate. In that case, the DM should rather rely on relative ranks that are re-assessed after the examination of each individual (see Section III-B).
We observe that, provided the DM knows the shape of the score distribution (i.e. partial-information), the learning of its parameters throughout the rounds is relatively fast, and the regret quickly converges to that of full-information (plain lines). Here, the strategy is much slower in converging towards the full-information case, which is achieved for r = 0 after approximately 40 rounds. The slow convergence is due to the DM’s inability to estimate each candidate’s absolute rank before having examined all other candidates (see Eq. 9).
V. CONCLUSION AND DISCUSSION
In this paper we presented a new algorithm, called Warmstarting Dynamic Thresholding (WDT), for the Warm-starting Sequential Selection Problem (WSSP), considering the case where the incoming candidates have scores following a known distribution. The proposed algorithm is based on a dynamic programming approach and achieves optimal threshold estimation at each step of the sequence of interviewed candidates. Experiments have been performed in the multi-round setting, which is interesting for real-world reoccurring recruitment processes. WDT demonstrated a clearly better performance than existing algorithms, regardless the number of initially

Fig. 2. Average regret φk versus the round number k. The number of job positions is b = 5 for n = 100 candidates per round. Score distribution: uniform, Si,k ∼ U (0, 1) (top row); exponential, Si,k ∼ Exp(1), ∀i, ∀k (bottom row). The number of initially empty job positions is r = 0 (left) and r = b = 5 (right). Purple lines use WDT in full-information (plain line), partial-information (dashed line) and no-information (dotted line) settings.
empty job positions. We additionally proposed a rank-based dynamic programming alternative that can go beyond the need of knowing perfectly the distribution that generates the scores, yet, resulting in satisfying outcomes.
REFERENCES
[1] M. Babaioff, N. Immorlica, D. Kempe, and R. Kleinberg, “A knapsack secretary problem with applications,” in APPROX-RANDOM, 2007.
[2] J. N. Bearden, A. Rapoport, and R. O. Murphy, “Experimental studies of sequential selection and assignment with relative ranks,” in Behavioral Decision Making, vol. 19, 2006, pp. 229–250.
[3] A. Z. Broder, A. Kirsch, R. Kumar, M. Mitzenmacher, E. Upfal, and S. Vassilvitskii, “The hiring problem and lake Wobegon strategies,” SIAM Journal on Computing, vol. 39, pp. 1223–1255, 2009.
[4] D. Chisca, M. Lombardi, M. Milano, and B. O’Sullivan, “From ofﬂine to online kidney exchange optimization,” IEEE International Conference on Tools with Artiﬁcial Intelligence, pp. 587–591, 2018.
[5] J. Das, F. Py, J. B. Harvey, J. P. Ryan, A. Gellene, R. Graham, D. A. Caron, K. Rajan, and G. S. Sukhatme, “Data-driven robotic sampling for marine ecosystem monitoring,” The International Journal of Robotics Research, vol. 34, no. 12, pp. 1435–1452, 2015.
[6] M. Fekom, N. Vayatis, and A. Kalogeratos, “The warm-starting sequential selection problem and its multi-round extension,” arXiv preprint, 2019.
[7] T. S. Ferguson, “Who solved the secretary problem?” in Statistical Science, 1989.
[8] A. Gnanlet and W. G. Gilland, “Sequential and simultaneous decision making for optimizing health care resource ﬂexibilities,” Decision Sciences, vol. 40, no. 2, pp. 295–326, 2009.
[9] R. Kleinberg, “A multiple-choice secretary algorithm with applications to online auctions,” in ACM-SIAM Symposium on Discrete Algorithms, 2005, pp. 630–631.
[10] D. V. Lindley, “Dynamic programming and decision theory,” in Applied Statistics, vol. 101, 1961, pp. 39–51.
[11] M. L. Nikolaev and G. Y. Sofronov, “A multiple optimal stopping rule for sums of independent random variables,” in Discrete Mathematics and Applications, vol. 17, no. 5, 2007.

